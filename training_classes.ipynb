{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":34905,"status":"ok","timestamp":1710337266936,"user":{"displayName":"Vincent Corbaux","userId":"05632967668149730282"},"user_tz":-60},"id":"TLb-bdfbjpGr","outputId":"af9856f6-e363-448a-d75b-1b407066428a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DVZ0u-L1jxIB"},"outputs":[],"source":["!pip install numpy scipy\n","!pip install matplotlib\n","!pip install tensorflow\n","#!pip install -U scikit-learn"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":14737,"status":"ok","timestamp":1710337292206,"user":{"displayName":"Vincent Corbaux","userId":"05632967668149730282"},"user_tz":-60},"id":"bjdphCk5jxUo"},"outputs":[],"source":["import matplotlib\n","import sys\n","sys.path.append('/content/drive/MyDrive/Age_Detection_Project/')\n","\n","from model.ResNet50 import AgeEstimatorModel as ResNetModel\n","from model.EfficientNetB0 import AgeEstimatorModel1 as EfficientNetModel\n","from model.VGGNet import AgeEstimatorModel3 as VGGNetModel\n","from model.AlexNetV2 import AlexNet2AgeClassifier as AlexNetModel\n","from model.CNNmodel import AgeEstimatorModel5 as CNNModel\n","from model.GoogleNet_new import GoogleNetNew as GoogleNetNew\n","from model.VGGNet_classifier import VGG_Classifier as VGG_Classifier\n","import tensorflow as tf\n","import keras\n","matplotlib.use(\"Agg\")\n","from keras.preprocessing.image import ImageDataGenerator\n","from keras.preprocessing.image import img_to_array\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import mean_squared_error, mean_absolute_error\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import random\n","import cv2\n","import glob\n","from scipy.stats import mode\n","import os.path\n","from torchvision import models\n","import torch.nn as nn\n","import torch\n","from keras.callbacks import LearningRateScheduler\n","from keras.optimizers.legacy import Adam\n","from keras.callbacks import LearningRateScheduler, EarlyStopping, ModelCheckpoint\n","from keras import layers\n","from PIL import Image\n","from io import BytesIO\n","from transformers import ViTFeatureExtractor, ViTForImageClassification\n","from tqdm import tqdm\n","from keras.utils import to_categorical"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1710337293312,"user":{"displayName":"Vincent Corbaux","userId":"05632967668149730282"},"user_tz":-60},"id":"R9avJBOJjxij"},"outputs":[],"source":["# Paths and parameters initialization\n","dataset_path = \"/content/drive/MyDrive/Age_Detection_Project/Faces\"\n","utkface_path = \"/content/drive/MyDrive/Age_Detection_Project/utkcropped\"\n","model_path_resnet = \"/content/drive/MyDrive/Age_Detection_Project/resnet_age_detection.model\"\n","model_path_effnet = \"/content/drive/MyDrive/Age_Detection_Project/effnet_age_detection.model\"\n","model_path_alexnet = \"/content/drive/MyDrive/Age_Detection_Project/AlexNet2_age_detection.model\"\n","model_path_vggnet = \"/content/drive/MyDrive/Age_Detection_Project/VGGNet_0.001_age_detection.model\"\n","model_path_googlenet = \"/content/drive/MyDrive/Age_Detection_Project/GoogleNet_age_detection.model\"\n","model_path_cnn = \"/content/drive/MyDrive/Age_Detection_Project/CNNModel_age_detection.model\"\n","plot_path_resnet = \"/content/drive/MyDrive/Age_Detection_Project/resnet_plot.png\"\n","plot_path_effnet = \"/content/drive/MyDrive/Age_Detection_Project/effnet_plot.png\"\n","plot_path_googlenet = \"/content/drive/MyDrive/Age_Detection_Project/googlenet_plot.png\"\n","plot_path_cnn = \"/content/drive/MyDrive/Age_Detection_Project/cnn_plot.png\"\n","plot_path_alexnet = \"/content/drive/MyDrive/Age_Detection_Project/alexnet_plot.png\"\n","plot_path_vggnet = \"/content/drive/MyDrive/Age_Detection_Project/vggnet_plot.png\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QdAQLjr8jxvk"},"outputs":[],"source":["images_0_17_path =\"/content/drive/MyDrive/Age_Detection_Project/0-17\"\n","images_18_25 = \"/content/drive/MyDrive/Age_Detection_Project/18-25\"\n","images_26_50 = \"/content/drive/MyDrive/Age_Detection_Project/26-50\"\n","image_51_70 = \"/content/drive/MyDrive/Age_Detection_Project/51-70\"\n","images_71_120 = \"/content/drive/MyDrive/Age_Detection_Project/71-120\""]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":119957,"status":"ok","timestamp":1710247163946,"user":{"displayName":"Vincent Corbaux","userId":"05632967668149730282"},"user_tz":-60},"id":"Iu9gEPEBkuHx","outputId":"8e4d2a96-0d78-4d2d-f90c-7eb38e499b9a"},"outputs":[{"name":"stdout","output_type":"stream","text":["1935\n","1935\n","[8, 15, 9, 7, 8, 2, 16, 3, 2, 7, 3, 3, 4, 2, 3, 2, 6, 5, 3, 2, 2, 16, 6, 13, 4, 9, 1, 2, 4, 6, 5, 2, 9, 9, 5, 9, 8, 1, 9, 1, 2, 10, 1, 9, 4, 4, 16, 8, 4, 1, 7, 2, 9, 16, 5, 4, 7, 7, 3, 2, 4, 16, 14, 3, 3, 7, 2, 6, 8, 9, 8, 15, 1, 8, 5, 2, 2, 4, 6, 5, 5, 1, 7, 4, 6, 4, 3, 3, 15, 3, 4, 12, 10, 3, 2, 5, 5, 3, 3, 7, 8, 2, 1, 8, 2, 1, 9, 14, 11, 8, 7, 9, 8, 7, 4, 6, 3, 2, 8, 1, 7, 14, 4, 9, 6, 6, 2, 16, 9, 2, 12, 3, 8, 16, 2, 5, 8, 2, 1, 4, 3, 5, 1, 8, 5, 6, 7, 2, 8, 14, 6, 14, 2, 3, 4, 3, 2, 8, 11, 17, 5, 3, 13, 10, 3, 1, 9, 5, 2, 4, 3, 5, 8, 1, 3, 3, 2, 2, 3, 16, 1, 4, 4, 4, 7, 1, 9, 11, 4, 15, 1, 9, 4, 7, 11, 2, 4, 3, 1, 17, 2, 9, 3, 8, 6, 15, 3, 6, 2, 6, 6, 9, 2, 9, 4, 2, 6, 4, 2, 3, 5, 8, 9, 4, 8, 17, 4, 2, 8, 2, 9, 2, 2, 16, 2, 5, 7, 8, 7, 2, 4, 4, 2, 3, 2, 16, 4, 2, 2, 4, 5, 1, 2, 7, 9, 2, 7, 7, 8, 2, 7, 16, 8, 6, 16, 1, 3, 8, 9, 6, 1, 3, 2, 8, 2, 2, 5, 3, 2, 17, 4, 8, 8, 2, 3, 4, 2, 8, 8, 4, 7, 2, 4, 11, 5, 9, 1, 2, 3, 2, 5, 2, 4, 2, 1, 5, 2, 1, 7, 3, 1, 4, 16, 5, 1, 3, 4, 1, 5, 5, 9, 5, 5, 2, 4, 9, 2, 5, 8, 2, 8, 3, 15, 6, 17, 2, 3, 14, 8, 10, 2, 2, 2, 1, 3, 12, 3, 2, 5, 16, 1, 4, 9, 8, 16, 4, 1, 2, 2, 5, 1, 2, 2, 17, 4, 9, 16, 8, 1, 4, 2, 5, 2, 7, 8, 16, 5, 10, 4, 5, 2, 1, 1, 16, 1, 4, 3, 2, 1, 8, 15, 8, 1, 6, 4, 2, 7, 6, 16, 1, 7, 6, 12, 2, 1, 9, 3, 9, 7, 8, 3, 6, 2, 7, 13, 2, 8, 9, 1, 1, 5, 8, 1, 1, 4, 7, 9, 1, 3, 15, 9, 3, 13, 2, 3, 8, 2, 8, 5, 16, 10, 2, 5, 9, 7, 7, 4, 3, 1, 2, 7, 1, 7, 2, 14, 15, 4, 1, 17, 3, 3, 2, 1, 8, 2, 10, 2, 2, 3, 1, 3, 6, 1, 4, 17, 8, 5, 8, 2, 5, 2, 8, 2, 3, 9, 8, 8, 2, 4, 9, 12, 1, 6, 5, 3, 9, 4, 2, 8, 8, 2, 15, 2, 2, 7, 5, 7, 4, 2, 4, 2, 13, 4, 4, 2, 6, 9, 7, 1, 3, 3, 12, 8, 5, 3, 3, 8, 5, 9, 3, 6, 5, 2, 8, 12, 6, 2, 3, 2, 1, 14, 9, 7, 2, 2, 16, 9, 3, 6, 5, 8, 1, 9, 4, 4, 16, 4, 8, 1, 2, 2, 16, 2, 2, 7, 8, 2, 8, 1, 4, 7, 7, 17, 3, 2, 8, 1, 6, 6, 2, 9, 2, 3, 5, 5, 4, 16, 1, 1, 2, 4, 2, 3, 4, 5, 6, 14, 8, 2, 2, 8, 6, 8, 4, 1, 4, 1, 6, 9, 9, 2, 4, 8, 1, 2, 4, 2, 4, 8, 4, 2, 3, 5, 3, 1, 15, 8, 3, 9, 15, 9, 2, 1, 9, 1, 6, 7, 3, 2, 11, 8, 2, 5, 7, 2, 8, 4, 7, 8, 17, 15, 1, 8, 4, 3, 1, 5, 3, 4, 6, 8, 1, 4, 8, 14, 3, 8, 2, 6, 3, 17, 8, 3, 6, 1, 1, 4, 3, 7, 2, 14, 17, 4, 2, 2, 17, 3, 2, 3, 4, 11, 6, 2, 6, 1, 9, 16, 5, 5, 4, 5, 5, 4, 17, 5, 6, 4, 1, 8, 2, 7, 4, 4, 8, 7, 4, 2, 7, 12, 12, 9, 3, 8, 2, 17, 7, 8, 9, 3, 9, 1, 5, 10, 14, 8, 8, 1, 2, 10, 1, 3, 5, 4, 5, 3, 5, 2, 2, 1, 2, 2, 2, 7, 2, 4, 15, 3, 4, 2, 8, 14, 2, 1, 3, 2, 2, 15, 1, 1, 6, 2, 2, 1, 1, 6, 2, 8, 3, 2, 4, 2, 16, 2, 5, 8, 2, 8, 4, 7, 3, 3, 2, 1, 2, 9, 1, 6, 5, 7, 16, 2, 8, 2, 9, 5, 12, 2, 4, 9, 10, 5, 3, 4, 8, 1, 9, 5, 8, 1, 5, 1, 1, 1, 8, 1, 13, 8, 9, 5, 8, 2, 3, 9, 5, 1, 2, 3, 8, 3, 2, 3, 13, 2, 4, 4, 5, 1, 7, 7, 2, 1, 12, 8, 10, 4, 2, 2, 8, 8, 8, 9, 12, 1, 8, 8, 7, 8, 1, 2, 2, 5, 3, 14, 16, 3, 2, 8, 2, 1, 8, 4, 3, 4, 17, 7, 5, 6, 2, 4, 15, 11, 1, 2, 2, 5, 8, 3, 8, 16, 9, 4, 12, 3, 1, 2, 4, 3, 4, 3, 7, 5, 1, 8, 4, 2, 8, 3, 8, 9, 1, 7, 1, 3, 5, 4, 1, 4, 4, 17, 6, 6, 10, 2, 10, 1, 8, 5, 8, 8, 12, 7, 1, 9, 6, 8, 2, 5, 8, 6, 13, 4, 4, 9, 7, 9, 3, 9, 1, 16, 7, 3, 4, 2, 10, 15, 13, 15, 6, 9, 3, 3, 10, 2, 2, 2, 2, 7, 4, 2, 9, 5, 8, 6, 8, 3, 1, 2, 8, 16, 5, 6, 3, 1, 7, 2, 2, 3, 1, 4, 6, 9, 9, 17, 6, 2, 3, 15, 14, 2, 1, 4, 1, 7, 15, 4, 5, 8, 8, 9, 17, 1, 1, 5, 2, 5, 5, 1, 1, 5, 17, 3, 1, 5, 3, 4, 1, 1, 16, 1, 2, 2, 4, 3, 1, 5, 9, 2, 15, 2, 2, 2, 2, 4, 2, 5, 17, 2, 2, 2, 1, 2, 4, 7, 9, 3, 9, 2, 2, 4, 1, 9, 2, 8, 1, 5, 8, 3, 7, 1, 4, 5, 1, 3, 6, 8, 1, 4, 1, 2, 2, 1, 5, 3, 4, 5, 1, 2, 2, 3, 15, 3, 4, 3, 4, 3, 8, 8, 3, 2, 3, 10, 6, 5, 4, 10, 1, 4, 2, 4, 4, 1, 4, 9, 9, 6, 8, 9, 7, 12, 2, 7, 4, 8, 2, 6, 9, 3, 4, 14, 8, 8, 2, 12, 8, 5, 1, 2, 15, 7, 7, 2, 1, 13, 3, 16, 8, 6, 2, 1, 4, 9, 2, 10, 6, 4, 8, 2, 3, 6, 8, 2, 2, 2, 5, 6, 7, 2, 2, 5, 5, 9, 2, 1, 1, 8, 8, 10, 2, 1, 3, 4, 12, 8, 6, 12, 3, 3, 1, 6, 8, 2, 16, 7, 10, 1, 2, 8, 2, 8, 1, 8, 1, 8, 4, 9, 8, 12, 5, 8, 3, 2, 16, 3, 7, 2, 14, 3, 4, 5, 1, 16, 4, 1, 16, 14, 8, 8, 9, 13, 2, 10, 8, 14, 4, 6, 1, 4, 1, 2, 5, 8, 1, 1, 2, 4, 2, 1, 1, 3, 2, 9, 8, 2, 1, 4, 3, 12, 5, 4, 3, 2, 3, 7, 11, 8, 1, 3, 2, 8, 4, 13, 1, 1, 10, 3, 10, 1, 2, 6, 14, 2, 3, 3, 13, 8, 5, 3, 8, 8, 4, 2, 9, 8, 6, 1, 2, 8, 1, 2, 3, 4, 2, 14, 17, 15, 4, 2, 8, 2, 14, 5, 6, 3, 2, 2, 1, 3, 3, 3, 2, 1, 3, 3, 14, 2, 1, 7, 4, 2, 1, 8, 5, 10, 1, 4, 1, 5, 2, 3, 8, 5, 10, 6, 2, 4, 4, 9, 2, 2, 1, 7, 7, 9, 2, 4, 4, 8, 2, 14, 14, 9, 15, 6, 2, 3, 9, 2, 9, 8, 16, 8, 1, 8, 2, 12, 2, 8, 7, 1, 4, 1, 8, 7, 2, 9, 1, 14, 13, 1, 1, 16, 6, 8, 17, 5, 8, 1, 2, 6, 1, 2, 6, 4, 15, 7, 2, 9, 3, 2, 3, 15, 16, 2, 6, 9, 4, 3, 2, 10, 6, 6, 4, 8, 10, 3, 3, 8, 8, 4, 11, 2, 6, 8, 7, 3, 1, 2, 3, 6, 7, 2, 3, 8, 2, 4, 4, 1, 5, 3, 5, 5, 9, 8, 4, 1, 3, 2, 1, 15, 1, 4, 1, 1, 5, 9, 16, 17, 5, 7, 8, 2, 1, 3, 2, 2, 8, 2, 3, 1, 2, 4, 7, 8, 1, 5, 1, 7, 14, 9, 2, 4, 2, 4, 5, 16, 3, 3, 8, 9, 5, 2, 13, 2, 2, 7, 8, 8, 2, 1, 1, 8, 2, 3, 2, 8, 4, 3, 8, 2, 1, 8, 3, 8, 4, 3, 1, 3, 14, 8, 1, 2, 5, 4, 5, 3, 16, 4, 5, 12, 4, 4, 1, 3, 5, 5, 8, 2, 8, 4, 2, 3, 5, 3, 2, 3, 9, 1, 2, 2, 3, 2, 2, 7, 2, 14, 2, 15, 5, 2, 15, 5, 8, 2, 3, 8, 4, 16, 1, 2, 8, 8, 4, 2, 5, 7, 3, 8, 5, 1, 11, 6, 3, 9, 9, 12, 5, 8, 2, 1, 8, 3, 2, 5, 5, 6, 2, 2, 2, 5, 9, 15, 2, 1, 8, 1, 2, 5, 9, 2, 3, 7, 6, 1, 13, 3, 3, 2, 7, 7, 2, 1, 2, 1, 1, 4, 6, 1, 6, 5, 1, 5, 3, 2, 5, 1, 7, 4, 6, 3, 4, 7, 1, 5, 5, 1, 5, 7, 4, 8, 6, 7, 2, 9, 1, 2, 2, 2, 5, 2, 8, 1, 1, 4, 4, 8, 9, 3, 1, 2, 4, 7, 2, 4, 2, 5, 6, 3, 2, 17, 5, 9, 1, 5, 1, 1, 5, 6, 2, 11, 7, 4, 4, 4, 8, 4, 6, 4, 5, 2, 17, 9, 7, 9, 8, 3, 7, 4, 3, 12, 4, 2, 2, 4, 1, 2, 2, 2, 16, 8, 4, 2, 7, 5, 2, 2, 9, 2, 4, 2, 17, 2, 9, 1, 3, 2, 4, 17, 4, 15, 16, 5, 4, 8, 2, 8, 4, 3, 4, 12, 9, 5, 2, 14, 4, 4, 8, 9, 3, 1, 3, 1, 3, 2, 2, 4, 8, 2, 1, 8, 2, 9, 11, 2, 2, 4, 2, 3, 3, 2, 8, 3, 2, 5, 1, 1, 4, 8, 6, 7, 8, 5, 6, 2, 8, 1, 2, 3, 3, 2, 3, 2, 14, 11, 10, 8, 2, 4, 16, 3, 3, 5, 2, 2, 2, 2, 2, 2, 15, 17, 9, 3, 6, 3, 9, 5, 5, 1, 9, 8, 9, 5, 1, 2, 4, 2, 4, 5, 2, 2, 3, 6, 9, 9, 3, 3, 6, 3, 3, 5, 14, 10, 4, 8, 2, 4, 6, 1, 4, 17, 9, 1, 10, 12, 5, 6, 1, 2, 1, 9, 7, 2, 1, 2, 13, 6, 2, 8, 9, 7, 1, 4, 4, 4, 4, 7, 2, 2, 2, 3, 3, 8, 4, 4, 1, 2, 2, 8, 6, 2, 4, 7, 4, 9, 2, 2, 10, 2, 7, 9, 1, 3, 2, 6, 15, 3]\n"]}],"source":["# Initial parameters\n","epochs = 100\n","lr = 0.001\n","batch_size = 64\n","img_dims = (96, 96, 3)\n","\n","# Load and preprocess the data\n","data = []\n","age_labels = []\n","\n","# Load image files from the dataset\n","image_files = [f for f in glob.glob(images_0_17_path + \"/*.jpg\", recursive=True)]\n","\n","print(len(image_files))\n","\n","random.seed(42)\n","random.shuffle(image_files)\n","\n","# Create ground-truth labels from the image paths\n","\n","for i in range(0,len(image_files)):\n","    image = cv2.imread(image_files[i])\n","    image = cv2.resize(image, (img_dims[0], img_dims[1]))\n","    image = img_to_array(image)\n","    data.append(image)\n","\n","    # Extract age labels from the image paths\n","    label = int(image_files[i].split(\"/\")[-1].split(\"_\")[0])\n","    age_labels.append(label)\n","\n","print(len(data))\n","print(age_labels)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":442,"status":"ok","timestamp":1710247164356,"user":{"displayName":"Vincent Corbaux","userId":"05632967668149730282"},"user_tz":-60},"id":"eJt5thI_k-Ni","outputId":"be815c7c-5f34-452a-dd06-ed1fcb043f3d"},"outputs":[{"name":"stdout","output_type":"stream","text":["Data shape: (1935, 96, 96, 3)\n","Labels shape: (1935,)\n"]}],"source":["# Pre-process the data\n","data = np.array(data, dtype=\"float\") / 255.0\n","labels = np.array(age_labels)\n","\n","\n","print(\"Data shape:\", data.shape)\n","print(\"Labels shape:\", labels.shape)\n","\n","# Split dataset for training and validation\n","(trainX, testX, trainY, testY) = train_test_split(data, labels, test_size=0.2, random_state=42)\n","\n","# Augmenting dataset\n","aug = ImageDataGenerator(rotation_range=25, width_shift_range=0.1,\n","                         height_shift_range=0.1, shear_range=0.2, zoom_range=0.2,\n","                         horizontal_flip=True, fill_mode=\"nearest\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"5cqN47AKlZ1I","outputId":"c01c0f02-981b-47d6-b06d-ba5149a60508"},"outputs":[{"name":"stdout","output_type":"stream","text":["Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n","94765736/94765736 [==============================] - 1s 0us/step\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/optimizers/legacy/adam.py:118: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n","  super().__init__(name, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 1/100\n","25/25 [==============================] - ETA: 0s - loss: 4.7953 - mae: 4.7953\n","Epoch 1: val_loss improved from inf to 22602.95312, saving model to best_model.h5\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"name":"stdout","output_type":"stream","text":["25/25 [==============================] - 282s 11s/step - loss: 4.7953 - mae: 4.7953 - val_loss: 22602.9531 - val_mae: 22602.9531\n","Epoch 2/100\n","25/25 [==============================] - ETA: 0s - loss: 2.8206 - mae: 2.8206\n","Epoch 2: val_loss improved from 22602.95312 to 1721.51453, saving model to best_model.h5\n","25/25 [==============================] - 262s 11s/step - loss: 2.8206 - mae: 2.8206 - val_loss: 1721.5145 - val_mae: 1721.5145\n","Epoch 3/100\n","25/25 [==============================] - ETA: 0s - loss: 2.5474 - mae: 2.5474 \n","Epoch 3: val_loss improved from 1721.51453 to 7.36769, saving model to best_model.h5\n","25/25 [==============================] - 267s 11s/step - loss: 2.5474 - mae: 2.5474 - val_loss: 7.3677 - val_mae: 7.3677\n","Epoch 4/100\n","25/25 [==============================] - ETA: 0s - loss: 2.5294 - mae: 2.5294\n","Epoch 4: val_loss improved from 7.36769 to 3.25909, saving model to best_model.h5\n","25/25 [==============================] - 254s 10s/step - loss: 2.5294 - mae: 2.5294 - val_loss: 3.2591 - val_mae: 3.2591\n","Epoch 5/100\n","25/25 [==============================] - ETA: 0s - loss: 2.3107 - mae: 2.3107\n","Epoch 5: val_loss did not improve from 3.25909\n","25/25 [==============================] - 254s 10s/step - loss: 2.3107 - mae: 2.3107 - val_loss: 454.2569 - val_mae: 454.2569\n","Epoch 6/100\n","25/25 [==============================] - ETA: 0s - loss: 2.4256 - mae: 2.4256\n","Epoch 6: val_loss did not improve from 3.25909\n","25/25 [==============================] - 264s 11s/step - loss: 2.4256 - mae: 2.4256 - val_loss: 6136.9097 - val_mae: 6136.9097\n","Epoch 7/100\n","25/25 [==============================] - ETA: 0s - loss: 2.2323 - mae: 2.2323\n","Epoch 7: val_loss did not improve from 3.25909\n","25/25 [==============================] - 247s 10s/step - loss: 2.2323 - mae: 2.2323 - val_loss: 761.6975 - val_mae: 761.6975\n","Epoch 8/100\n","25/25 [==============================] - ETA: 0s - loss: 2.2126 - mae: 2.2126\n","Epoch 8: val_loss did not improve from 3.25909\n","25/25 [==============================] - 262s 11s/step - loss: 2.2126 - mae: 2.2126 - val_loss: 3.4940 - val_mae: 3.4940\n","Epoch 9/100\n","25/25 [==============================] - ETA: 0s - loss: 2.2404 - mae: 2.2404\n","Epoch 9: val_loss did not improve from 3.25909\n","25/25 [==============================] - 264s 11s/step - loss: 2.2404 - mae: 2.2404 - val_loss: 34.1158 - val_mae: 34.1158\n","Epoch 10/100\n","25/25 [==============================] - ETA: 0s - loss: 2.3932 - mae: 2.3932\n","Epoch 10: val_loss did not improve from 3.25909\n","25/25 [==============================] - 264s 11s/step - loss: 2.3932 - mae: 2.3932 - val_loss: 4.1181 - val_mae: 4.1181\n","Epoch 11/100\n","13/25 [==============>...............] - ETA: 2:00 - loss: 2.5013 - mae: 2.5013"]}],"source":["# build and train ResNet50 model\n","model_resnet = ResNetModel.build(width=img_dims[0], height=img_dims[1], depth=img_dims[2], classes=1)\n","#H_resnet = train_model(model_resnet, \"ResNet50\")\n","\n","# Compile the model\n","optimizer = Adam(lr=0.001)\n","model_resnet.compile(loss='mean_absolute_error',\n","              optimizer=optimizer,\n","              metrics=['mae'])\n","\n","callbacks = [\n","    EarlyStopping(monitor='val_loss', patience=10, verbose=1, restore_best_weights=True),\n","    ModelCheckpoint(filepath='best_model.h5', monitor='val_loss', save_best_only=True, verbose=1)\n","]\n","\n","# Train the model with learning rate scheduler callback\n","# Train the model with callbacks\n","model_resnet.fit(aug.flow(trainX, trainY, batch_size=batch_size),\n","                    epochs=100,\n","                    validation_data=(testX, testY),\n","                    callbacks=callbacks)\n","\n","pred = model_resnet.predict(np.array(testX))\n","mae = mean_absolute_error(testY, pred)\n","\n","print(\"Mean Absolute Error for resnet\", mae)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RUkFLo3pmMjl"},"outputs":[],"source":["# build and train EfficientNetB0 model\n","model_effnet = EfficientNetModel.build(width=img_dims[0], height=img_dims[1], depth=img_dims[2], classes=1)\n","#H_effnet = train_model(model_effnet, \"EfficientNetB0\")\n","\n","# Compile the model\n","optimizer = Adam(lr=0.001)\n","model_effnet.compile(loss='mean_absolute_error',\n","              optimizer=optimizer,\n","              metrics=['mae'])\n","\n","callbacks = [\n","    EarlyStopping(monitor='val_loss', patience=10, verbose=1, restore_best_weights=True),\n","    ModelCheckpoint(filepath='best_model.h5', monitor='val_loss', save_best_only=True, verbose=1)\n","]\n","\n","# Train the model with learning rate scheduler callback\n","# Train the model with callbacks\n","model_effnet.fit(aug.flow(trainX, trainY, batch_size=batch_size),\n","                    epochs=100,\n","                    validation_data=(testX, testY),\n","                    callbacks=callbacks)\n","\n","pred = model_effnet.predict(np.array(testX))\n","mae = mean_absolute_error(testY, pred)\n","\n","print(\"Mean Absolute Error for effnet\", mae)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lvvDNOo0mWSS"},"outputs":[],"source":["# build and train GoogleNet model\n","model_googlenet = GoogleNetNew.GoogLeNet()\n","#H_googlenet = train_model(model_googlenet, \"GoogleNet\")\n","# Compile the model\n","optimizer = Adam(lr=0.0001)\n","model_googlenet.compile(loss='mean_absolute_error',\n","              optimizer=optimizer,\n","              metrics=['mae'])\n","\n","callbacks = [\n","    EarlyStopping(monitor='val_loss', patience=10, verbose=1, restore_best_weights=True),\n","    ModelCheckpoint(filepath='best_model.h5', monitor='val_loss', save_best_only=True, verbose=1)\n","]\n","\n","# Train the model with learning rate scheduler callback\n","# Train the model with callbacks\n","model_googlenet.fit(aug.flow(trainX, trainY, batch_size=batch_size),\n","                    epochs=100,\n","                    validation_data=(testX, testY),\n","                    callbacks=callbacks)\n","\n","pred = model_googlenet.predict(np.array(testX))\n","mae = mean_absolute_error(testY, pred)\n","\n","print(\"Mean Absolute Error for googlenet\", mae)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"SiDjyELXn2d-","outputId":"db4c397b-7b85-4fd1-e841-8e2545e6694a"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/optimizers/legacy/adam.py:118: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n","  super().__init__(name, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 1/100\n","33/33 [==============================] - ETA: 0s - loss: 45.3679 - mae: 45.3679\n","Epoch 1: val_loss improved from inf to 6.81034, saving model to best_model.h5\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"name":"stdout","output_type":"stream","text":["33/33 [==============================] - 11s 320ms/step - loss: 45.3679 - mae: 45.3679 - val_loss: 6.8103 - val_mae: 6.8103\n","Epoch 2/100\n","33/33 [==============================] - ETA: 0s - loss: 5.6932 - mae: 5.6932\n","Epoch 2: val_loss improved from 6.81034 to 5.07219, saving model to best_model.h5\n","33/33 [==============================] - 6s 171ms/step - loss: 5.6932 - mae: 5.6932 - val_loss: 5.0722 - val_mae: 5.0722\n","Epoch 3/100\n","33/33 [==============================] - ETA: 0s - loss: 5.5336 - mae: 5.5336\n","Epoch 3: val_loss improved from 5.07219 to 4.90194, saving model to best_model.h5\n","33/33 [==============================] - 6s 168ms/step - loss: 5.5336 - mae: 5.5336 - val_loss: 4.9019 - val_mae: 4.9019\n","Epoch 4/100\n","33/33 [==============================] - ETA: 0s - loss: 5.8753 - mae: 5.8753\n","Epoch 4: val_loss did not improve from 4.90194\n","33/33 [==============================] - 5s 159ms/step - loss: 5.8753 - mae: 5.8753 - val_loss: 5.1939 - val_mae: 5.1939\n","Epoch 5/100\n","33/33 [==============================] - ETA: 0s - loss: 5.6458 - mae: 5.6458\n","Epoch 5: val_loss did not improve from 4.90194\n","33/33 [==============================] - 5s 153ms/step - loss: 5.6458 - mae: 5.6458 - val_loss: 5.5089 - val_mae: 5.5089\n","Epoch 6/100\n","33/33 [==============================] - ETA: 0s - loss: 5.7702 - mae: 5.7702\n","Epoch 6: val_loss did not improve from 4.90194\n","33/33 [==============================] - 5s 157ms/step - loss: 5.7702 - mae: 5.7702 - val_loss: 5.3374 - val_mae: 5.3374\n","Epoch 7/100\n","33/33 [==============================] - ETA: 0s - loss: 5.5319 - mae: 5.5319\n","Epoch 7: val_loss did not improve from 4.90194\n","33/33 [==============================] - 5s 157ms/step - loss: 5.5319 - mae: 5.5319 - val_loss: 5.2899 - val_mae: 5.2899\n","Epoch 8/100\n","33/33 [==============================] - ETA: 0s - loss: 5.3970 - mae: 5.3970\n","Epoch 8: val_loss did not improve from 4.90194\n","33/33 [==============================] - 5s 152ms/step - loss: 5.3970 - mae: 5.3970 - val_loss: 5.0101 - val_mae: 5.0101\n","Epoch 9/100\n","33/33 [==============================] - ETA: 0s - loss: 5.3871 - mae: 5.3871\n","Epoch 9: val_loss improved from 4.90194 to 4.86623, saving model to best_model.h5\n","33/33 [==============================] - 6s 173ms/step - loss: 5.3871 - mae: 5.3871 - val_loss: 4.8662 - val_mae: 4.8662\n","Epoch 10/100\n","33/33 [==============================] - ETA: 0s - loss: 5.2997 - mae: 5.2997\n","Epoch 10: val_loss improved from 4.86623 to 4.80723, saving model to best_model.h5\n","33/33 [==============================] - 6s 166ms/step - loss: 5.2997 - mae: 5.2997 - val_loss: 4.8072 - val_mae: 4.8072\n","Epoch 11/100\n","33/33 [==============================] - ETA: 0s - loss: 5.1878 - mae: 5.1878\n","Epoch 11: val_loss did not improve from 4.80723\n","33/33 [==============================] - 5s 158ms/step - loss: 5.1878 - mae: 5.1878 - val_loss: 4.9995 - val_mae: 4.9995\n","Epoch 12/100\n","33/33 [==============================] - ETA: 0s - loss: 5.2408 - mae: 5.2408\n","Epoch 12: val_loss did not improve from 4.80723\n","33/33 [==============================] - 5s 160ms/step - loss: 5.2408 - mae: 5.2408 - val_loss: 4.8600 - val_mae: 4.8600\n","Epoch 13/100\n","33/33 [==============================] - ETA: 0s - loss: 5.2192 - mae: 5.2192\n","Epoch 13: val_loss improved from 4.80723 to 4.79868, saving model to best_model.h5\n","33/33 [==============================] - 6s 173ms/step - loss: 5.2192 - mae: 5.2192 - val_loss: 4.7987 - val_mae: 4.7987\n","Epoch 14/100\n","33/33 [==============================] - ETA: 0s - loss: 5.5787 - mae: 5.5787\n","Epoch 14: val_loss did not improve from 4.79868\n","33/33 [==============================] - 5s 154ms/step - loss: 5.5787 - mae: 5.5787 - val_loss: 5.2018 - val_mae: 5.2018\n","Epoch 15/100\n","33/33 [==============================] - ETA: 0s - loss: 5.2213 - mae: 5.2213\n","Epoch 15: val_loss did not improve from 4.79868\n","33/33 [==============================] - 5s 151ms/step - loss: 5.2213 - mae: 5.2213 - val_loss: 5.1350 - val_mae: 5.1350\n","Epoch 16/100\n","33/33 [==============================] - ETA: 0s - loss: 5.3692 - mae: 5.3692\n","Epoch 16: val_loss did not improve from 4.79868\n","33/33 [==============================] - 5s 155ms/step - loss: 5.3692 - mae: 5.3692 - val_loss: 5.1962 - val_mae: 5.1962\n","Epoch 17/100\n","33/33 [==============================] - ETA: 0s - loss: 5.4676 - mae: 5.4676\n","Epoch 17: val_loss did not improve from 4.79868\n","33/33 [==============================] - 5s 155ms/step - loss: 5.4676 - mae: 5.4676 - val_loss: 5.1777 - val_mae: 5.1777\n","Epoch 18/100\n","33/33 [==============================] - ETA: 0s - loss: 5.6556 - mae: 5.6556\n","Epoch 18: val_loss did not improve from 4.79868\n","33/33 [==============================] - 5s 156ms/step - loss: 5.6556 - mae: 5.6556 - val_loss: 5.0908 - val_mae: 5.0908\n","Epoch 19/100\n","33/33 [==============================] - ETA: 0s - loss: 5.3650 - mae: 5.3650\n","Epoch 19: val_loss did not improve from 4.79868\n","33/33 [==============================] - 5s 151ms/step - loss: 5.3650 - mae: 5.3650 - val_loss: 4.8776 - val_mae: 4.8776\n","Epoch 20/100\n","33/33 [==============================] - ETA: 0s - loss: 5.3878 - mae: 5.3878\n","Epoch 20: val_loss did not improve from 4.79868\n","33/33 [==============================] - 5s 156ms/step - loss: 5.3878 - mae: 5.3878 - val_loss: 4.8717 - val_mae: 4.8717\n","Epoch 21/100\n","33/33 [==============================] - ETA: 0s - loss: 5.3537 - mae: 5.3537\n","Epoch 21: val_loss did not improve from 4.79868\n","33/33 [==============================] - 5s 158ms/step - loss: 5.3537 - mae: 5.3537 - val_loss: 5.1840 - val_mae: 5.1840\n","Epoch 22/100\n","33/33 [==============================] - ETA: 0s - loss: 5.4346 - mae: 5.4346\n","Epoch 22: val_loss did not improve from 4.79868\n","33/33 [==============================] - 5s 156ms/step - loss: 5.4346 - mae: 5.4346 - val_loss: 5.2569 - val_mae: 5.2569\n","Epoch 23/100\n","33/33 [==============================] - ETA: 0s - loss: 5.1650 - mae: 5.1650Restoring model weights from the end of the best epoch: 13.\n","\n","Epoch 23: val_loss did not improve from 4.79868\n","33/33 [==============================] - 5s 160ms/step - loss: 5.1650 - mae: 5.1650 - val_loss: 5.0153 - val_mae: 5.0153\n","Epoch 23: early stopping\n","17/17 [==============================] - 0s 9ms/step\n","Mean Absolute Error for vggnet 4.798680972144718\n"]}],"source":["# build and train VGGNet model\n","model_vggnet = VGGNetModel.build(width=img_dims[0], height=img_dims[1], depth=img_dims[2], classes=1)\n","#H_vggnet = train_model(model_vggnet, \"VGGNet\")\n","\n","# Compile the model\n","optimizer = Adam(lr=0.001)\n","model_vggnet.compile(loss='mean_absolute_error',\n","              optimizer=optimizer,\n","              metrics=['mae'])\n","\n","callbacks = [\n","    EarlyStopping(monitor='val_loss', patience=10, verbose=1, restore_best_weights=True),\n","    ModelCheckpoint(filepath='best_model.h5', monitor='val_loss', save_best_only=True, verbose=1)\n","]\n","\n","# Train the model with learning rate scheduler callback\n","# Train the model with callbacks\n","model_vggnet.fit(aug.flow(trainX, trainY, batch_size=batch_size),\n","                    epochs=100,\n","                    validation_data=(testX, testY),\n","                    callbacks=callbacks)\n","\n","\n","pred = model_vggnet.predict(np.array(testX))\n","mae = mean_absolute_error(testY, pred)\n","\n","print(\"Mean Absolute Error for vggnet\", mae)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"PzZQUmMyoBnF","outputId":"bb497179-4290-4174-8b3b-f9f7f46526ed"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/optimizers/legacy/adam.py:118: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n","  super().__init__(name, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 1/100\n","33/33 [==============================] - ETA: 0s - loss: 57.7825 - mae: 57.7825\n","Epoch 1: val_loss improved from inf to 56.81759, saving model to best_model.h5\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"name":"stdout","output_type":"stream","text":["33/33 [==============================] - 8s 214ms/step - loss: 57.7825 - mae: 57.7825 - val_loss: 56.8176 - val_mae: 56.8176\n","Epoch 2/100\n","33/33 [==============================] - ETA: 0s - loss: 53.3518 - mae: 53.3518\n","Epoch 2: val_loss improved from 56.81759 to 50.42168, saving model to best_model.h5\n","33/33 [==============================] - 6s 178ms/step - loss: 53.3518 - mae: 53.3518 - val_loss: 50.4217 - val_mae: 50.4217\n","Epoch 3/100\n","33/33 [==============================] - ETA: 0s - loss: 44.1876 - mae: 44.1876\n","Epoch 3: val_loss improved from 50.42168 to 38.72923, saving model to best_model.h5\n","33/33 [==============================] - 6s 182ms/step - loss: 44.1876 - mae: 44.1876 - val_loss: 38.7292 - val_mae: 38.7292\n","Epoch 4/100\n","33/33 [==============================] - ETA: 0s - loss: 30.7674 - mae: 30.7674\n","Epoch 4: val_loss did not improve from 38.72923\n","33/33 [==============================] - 5s 148ms/step - loss: 30.7674 - mae: 30.7674 - val_loss: 907.3552 - val_mae: 907.3552\n","Epoch 5/100\n","33/33 [==============================] - ETA: 0s - loss: 14.4689 - mae: 14.4689\n","Epoch 5: val_loss did not improve from 38.72923\n","33/33 [==============================] - 5s 147ms/step - loss: 14.4689 - mae: 14.4689 - val_loss: 2378.1230 - val_mae: 2378.1230\n","Epoch 6/100\n","33/33 [==============================] - ETA: 0s - loss: 6.8710 - mae: 6.8710\n","Epoch 6: val_loss did not improve from 38.72923\n","33/33 [==============================] - 5s 148ms/step - loss: 6.8710 - mae: 6.8710 - val_loss: 630.8698 - val_mae: 630.8698\n","Epoch 7/100\n","33/33 [==============================] - ETA: 0s - loss: 6.6665 - mae: 6.6665\n","Epoch 7: val_loss did not improve from 38.72923\n","33/33 [==============================] - 5s 146ms/step - loss: 6.6665 - mae: 6.6665 - val_loss: 102.3400 - val_mae: 102.3400\n","Epoch 8/100\n","33/33 [==============================] - ETA: 0s - loss: 6.2706 - mae: 6.2706\n","Epoch 8: val_loss improved from 38.72923 to 33.82957, saving model to best_model.h5\n","33/33 [==============================] - 6s 181ms/step - loss: 6.2706 - mae: 6.2706 - val_loss: 33.8296 - val_mae: 33.8296\n","Epoch 9/100\n","33/33 [==============================] - ETA: 0s - loss: 6.1737 - mae: 6.1737\n","Epoch 9: val_loss improved from 33.82957 to 6.74509, saving model to best_model.h5\n","33/33 [==============================] - 6s 178ms/step - loss: 6.1737 - mae: 6.1737 - val_loss: 6.7451 - val_mae: 6.7451\n","Epoch 10/100\n","33/33 [==============================] - ETA: 0s - loss: 6.2497 - mae: 6.2497\n","Epoch 10: val_loss did not improve from 6.74509\n","33/33 [==============================] - 5s 153ms/step - loss: 6.2497 - mae: 6.2497 - val_loss: 6.9815 - val_mae: 6.9815\n","Epoch 11/100\n","33/33 [==============================] - ETA: 0s - loss: 6.3147 - mae: 6.3147\n","Epoch 11: val_loss improved from 6.74509 to 5.94441, saving model to best_model.h5\n","33/33 [==============================] - 6s 177ms/step - loss: 6.3147 - mae: 6.3147 - val_loss: 5.9444 - val_mae: 5.9444\n","Epoch 12/100\n","33/33 [==============================] - ETA: 0s - loss: 6.1258 - mae: 6.1258\n","Epoch 12: val_loss improved from 5.94441 to 5.70832, saving model to best_model.h5\n","33/33 [==============================] - 6s 184ms/step - loss: 6.1258 - mae: 6.1258 - val_loss: 5.7083 - val_mae: 5.7083\n","Epoch 13/100\n","33/33 [==============================] - ETA: 0s - loss: 6.2149 - mae: 6.2149\n","Epoch 13: val_loss improved from 5.70832 to 4.94899, saving model to best_model.h5\n","33/33 [==============================] - 6s 180ms/step - loss: 6.2149 - mae: 6.2149 - val_loss: 4.9490 - val_mae: 4.9490\n","Epoch 14/100\n","33/33 [==============================] - ETA: 0s - loss: 6.1020 - mae: 6.1020\n","Epoch 14: val_loss did not improve from 4.94899\n","33/33 [==============================] - 5s 156ms/step - loss: 6.1020 - mae: 6.1020 - val_loss: 5.0729 - val_mae: 5.0729\n","Epoch 15/100\n","33/33 [==============================] - ETA: 0s - loss: 6.0726 - mae: 6.0726\n","Epoch 15: val_loss did not improve from 4.94899\n","33/33 [==============================] - 5s 152ms/step - loss: 6.0726 - mae: 6.0726 - val_loss: 5.1552 - val_mae: 5.1552\n","Epoch 16/100\n","33/33 [==============================] - ETA: 0s - loss: 6.0317 - mae: 6.0317\n","Epoch 16: val_loss improved from 4.94899 to 4.85635, saving model to best_model.h5\n","33/33 [==============================] - 6s 184ms/step - loss: 6.0317 - mae: 6.0317 - val_loss: 4.8563 - val_mae: 4.8563\n","Epoch 17/100\n","33/33 [==============================] - ETA: 0s - loss: 5.8201 - mae: 5.8201\n","Epoch 17: val_loss improved from 4.85635 to 4.79697, saving model to best_model.h5\n","33/33 [==============================] - 6s 182ms/step - loss: 5.8201 - mae: 5.8201 - val_loss: 4.7970 - val_mae: 4.7970\n","Epoch 18/100\n","33/33 [==============================] - ETA: 0s - loss: 5.9703 - mae: 5.9703\n","Epoch 18: val_loss did not improve from 4.79697\n","33/33 [==============================] - 5s 154ms/step - loss: 5.9703 - mae: 5.9703 - val_loss: 5.0780 - val_mae: 5.0780\n","Epoch 19/100\n","33/33 [==============================] - ETA: 0s - loss: 5.9765 - mae: 5.9765\n","Epoch 19: val_loss did not improve from 4.79697\n","33/33 [==============================] - 5s 152ms/step - loss: 5.9765 - mae: 5.9765 - val_loss: 4.8570 - val_mae: 4.8570\n","Epoch 20/100\n","33/33 [==============================] - ETA: 0s - loss: 5.8730 - mae: 5.8730\n","Epoch 20: val_loss did not improve from 4.79697\n","33/33 [==============================] - 5s 147ms/step - loss: 5.8730 - mae: 5.8730 - val_loss: 5.1298 - val_mae: 5.1298\n","Epoch 21/100\n","33/33 [==============================] - ETA: 0s - loss: 5.8328 - mae: 5.8328\n","Epoch 21: val_loss did not improve from 4.79697\n","33/33 [==============================] - 5s 154ms/step - loss: 5.8328 - mae: 5.8328 - val_loss: 5.6364 - val_mae: 5.6364\n","Epoch 22/100\n","33/33 [==============================] - ETA: 0s - loss: 5.8952 - mae: 5.8952\n","Epoch 22: val_loss did not improve from 4.79697\n","33/33 [==============================] - 5s 147ms/step - loss: 5.8952 - mae: 5.8952 - val_loss: 4.8743 - val_mae: 4.8743\n","Epoch 23/100\n","33/33 [==============================] - ETA: 0s - loss: 5.6591 - mae: 5.6591\n","Epoch 23: val_loss did not improve from 4.79697\n","33/33 [==============================] - 5s 150ms/step - loss: 5.6591 - mae: 5.6591 - val_loss: 4.8632 - val_mae: 4.8632\n","Epoch 24/100\n","33/33 [==============================] - ETA: 0s - loss: 5.7002 - mae: 5.7002\n","Epoch 24: val_loss did not improve from 4.79697\n","33/33 [==============================] - 5s 147ms/step - loss: 5.7002 - mae: 5.7002 - val_loss: 5.0918 - val_mae: 5.0918\n","Epoch 25/100\n","33/33 [==============================] - ETA: 0s - loss: 5.6337 - mae: 5.6337\n","Epoch 25: val_loss did not improve from 4.79697\n","33/33 [==============================] - 5s 146ms/step - loss: 5.6337 - mae: 5.6337 - val_loss: 5.4346 - val_mae: 5.4346\n","Epoch 26/100\n","33/33 [==============================] - ETA: 0s - loss: 5.4699 - mae: 5.4699\n","Epoch 26: val_loss did not improve from 4.79697\n","33/33 [==============================] - 5s 152ms/step - loss: 5.4699 - mae: 5.4699 - val_loss: 5.0048 - val_mae: 5.0048\n","Epoch 27/100\n","33/33 [==============================] - ETA: 0s - loss: 5.8121 - mae: 5.8121Restoring model weights from the end of the best epoch: 17.\n","\n","Epoch 27: val_loss did not improve from 4.79697\n","33/33 [==============================] - 5s 154ms/step - loss: 5.8121 - mae: 5.8121 - val_loss: 5.3077 - val_mae: 5.3077\n","Epoch 27: early stopping\n","17/17 [==============================] - 0s 3ms/step\n","Mean Absolute Error for AlexNet 4.79696767897833\n"]}],"source":["# build and train AlexNet model\n","model_alexnet2 = AlexNetModel.build(width=img_dims[0], height=img_dims[1], depth=img_dims[2], classes=1)\n","#H_alexnet2 = train_model(model_alexnet2, \"AlexNet2\")\n","# Compile the model\n","optimizer = Adam(lr=0.001)\n","model_alexnet2.compile(loss='mean_absolute_error',\n","              optimizer=optimizer,\n","              metrics=['mae'])\n","\n","callbacks = [\n","    EarlyStopping(monitor='val_loss', patience=10, verbose=1, restore_best_weights=True),\n","    ModelCheckpoint(filepath='best_model.h5', monitor='val_loss', save_best_only=True, verbose=1)\n","]\n","\n","# Train the model with learning rate scheduler callback\n","# Train the model with callbacks\n","model_alexnet2.fit(aug.flow(trainX, trainY, batch_size=batch_size),\n","                    epochs=100,\n","                    validation_data=(testX, testY),\n","                    callbacks=callbacks)\n","\n","\n","pred = model_alexnet2.predict(np.array(testX))\n","mae = mean_absolute_error(testY, pred)\n","\n","print(\"Mean Absolute Error for AlexNet\", mae)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"ofVZi9KKoJLS","outputId":"455f5ce4-bb95-44d6-8c6b-fe847459e440"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/optimizers/legacy/adam.py:118: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n","  super().__init__(name, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 1/100\n","33/33 [==============================] - ETA: 0s - loss: 16.0386 - mae: 16.0386\n","Epoch 1: val_loss improved from inf to 8.74715, saving model to best_model.h5\n","33/33 [==============================] - 2s 49ms/step - loss: 16.0386 - mae: 16.0386 - val_loss: 8.7471 - val_mae: 8.7471\n","Epoch 2/100\n","13/33 [==========>...................] - ETA: 0s - loss: 7.8743 - mae: 7.8743"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"name":"stdout","output_type":"stream","text":["31/33 [===========================>..] - ETA: 0s - loss: 7.8590 - mae: 7.8590\n","Epoch 2: val_loss improved from 8.74715 to 7.05171, saving model to best_model.h5\n","33/33 [==============================] - 0s 13ms/step - loss: 7.8306 - mae: 7.8306 - val_loss: 7.0517 - val_mae: 7.0517\n","Epoch 3/100\n","31/33 [===========================>..] - ETA: 0s - loss: 6.9744 - mae: 6.9744\n","Epoch 3: val_loss did not improve from 7.05171\n","33/33 [==============================] - 0s 12ms/step - loss: 6.9389 - mae: 6.9389 - val_loss: 8.1696 - val_mae: 8.1696\n","Epoch 4/100\n","31/33 [===========================>..] - ETA: 0s - loss: 6.5289 - mae: 6.5289\n","Epoch 4: val_loss improved from 7.05171 to 5.72368, saving model to best_model.h5\n","33/33 [==============================] - 0s 13ms/step - loss: 6.5336 - mae: 6.5336 - val_loss: 5.7237 - val_mae: 5.7237\n","Epoch 5/100\n","31/33 [===========================>..] - ETA: 0s - loss: 6.1913 - mae: 6.1913\n","Epoch 5: val_loss improved from 5.72368 to 5.16669, saving model to best_model.h5\n","33/33 [==============================] - 0s 13ms/step - loss: 6.1779 - mae: 6.1779 - val_loss: 5.1667 - val_mae: 5.1667\n","Epoch 6/100\n","31/33 [===========================>..] - ETA: 0s - loss: 5.4117 - mae: 5.4117\n","Epoch 6: val_loss improved from 5.16669 to 5.00323, saving model to best_model.h5\n","33/33 [==============================] - 0s 13ms/step - loss: 5.4218 - mae: 5.4218 - val_loss: 5.0032 - val_mae: 5.0032\n","Epoch 7/100\n","31/33 [===========================>..] - ETA: 0s - loss: 5.6272 - mae: 5.6272\n","Epoch 7: val_loss improved from 5.00323 to 5.00051, saving model to best_model.h5\n","33/33 [==============================] - 0s 13ms/step - loss: 5.5905 - mae: 5.5905 - val_loss: 5.0005 - val_mae: 5.0005\n","Epoch 8/100\n","31/33 [===========================>..] - ETA: 0s - loss: 5.3932 - mae: 5.3932\n","Epoch 8: val_loss did not improve from 5.00051\n","33/33 [==============================] - 0s 11ms/step - loss: 5.3756 - mae: 5.3756 - val_loss: 5.0529 - val_mae: 5.0529\n","Epoch 9/100\n","31/33 [===========================>..] - ETA: 0s - loss: 5.2317 - mae: 5.2317\n","Epoch 9: val_loss did not improve from 5.00051\n","33/33 [==============================] - 0s 11ms/step - loss: 5.2387 - mae: 5.2387 - val_loss: 5.2828 - val_mae: 5.2828\n","Epoch 10/100\n","31/33 [===========================>..] - ETA: 0s - loss: 6.0765 - mae: 6.0765\n","Epoch 10: val_loss did not improve from 5.00051\n","33/33 [==============================] - 0s 11ms/step - loss: 6.0014 - mae: 6.0014 - val_loss: 5.3477 - val_mae: 5.3477\n","Epoch 11/100\n","31/33 [===========================>..] - ETA: 0s - loss: 5.0839 - mae: 5.0839\n","Epoch 11: val_loss improved from 5.00051 to 4.92711, saving model to best_model.h5\n","33/33 [==============================] - 0s 15ms/step - loss: 5.0794 - mae: 5.0794 - val_loss: 4.9271 - val_mae: 4.9271\n","Epoch 12/100\n","31/33 [===========================>..] - ETA: 0s - loss: 4.9110 - mae: 4.9110\n","Epoch 12: val_loss improved from 4.92711 to 4.85070, saving model to best_model.h5\n","33/33 [==============================] - 0s 13ms/step - loss: 4.9319 - mae: 4.9319 - val_loss: 4.8507 - val_mae: 4.8507\n","Epoch 13/100\n","31/33 [===========================>..] - ETA: 0s - loss: 5.1225 - mae: 5.1225\n","Epoch 13: val_loss did not improve from 4.85070\n","33/33 [==============================] - 0s 11ms/step - loss: 5.0933 - mae: 5.0933 - val_loss: 5.2567 - val_mae: 5.2567\n","Epoch 14/100\n","31/33 [===========================>..] - ETA: 0s - loss: 4.8526 - mae: 4.8526\n","Epoch 14: val_loss improved from 4.85070 to 4.82814, saving model to best_model.h5\n","33/33 [==============================] - 0s 13ms/step - loss: 4.8186 - mae: 4.8186 - val_loss: 4.8281 - val_mae: 4.8281\n","Epoch 15/100\n","30/33 [==========================>...] - ETA: 0s - loss: 5.0052 - mae: 5.0052\n","Epoch 15: val_loss did not improve from 4.82814\n","33/33 [==============================] - 0s 11ms/step - loss: 5.0126 - mae: 5.0126 - val_loss: 5.0622 - val_mae: 5.0622\n","Epoch 16/100\n","31/33 [===========================>..] - ETA: 0s - loss: 4.9580 - mae: 4.9580\n","Epoch 16: val_loss did not improve from 4.82814\n","33/33 [==============================] - 0s 11ms/step - loss: 4.9388 - mae: 4.9388 - val_loss: 5.0690 - val_mae: 5.0690\n","Epoch 17/100\n","31/33 [===========================>..] - ETA: 0s - loss: 5.0706 - mae: 5.0706\n","Epoch 17: val_loss did not improve from 4.82814\n","33/33 [==============================] - 0s 11ms/step - loss: 5.0529 - mae: 5.0529 - val_loss: 4.9333 - val_mae: 4.9333\n","Epoch 18/100\n","31/33 [===========================>..] - ETA: 0s - loss: 4.9524 - mae: 4.9524\n","Epoch 18: val_loss did not improve from 4.82814\n","33/33 [==============================] - 0s 11ms/step - loss: 4.9408 - mae: 4.9408 - val_loss: 4.9175 - val_mae: 4.9175\n","Epoch 19/100\n","31/33 [===========================>..] - ETA: 0s - loss: 5.3526 - mae: 5.3526\n","Epoch 19: val_loss did not improve from 4.82814\n","33/33 [==============================] - 0s 11ms/step - loss: 5.3689 - mae: 5.3689 - val_loss: 5.5569 - val_mae: 5.5569\n","Epoch 20/100\n","31/33 [===========================>..] - ETA: 0s - loss: 5.1868 - mae: 5.1868\n","Epoch 20: val_loss did not improve from 4.82814\n","33/33 [==============================] - 0s 11ms/step - loss: 5.2042 - mae: 5.2042 - val_loss: 5.1313 - val_mae: 5.1313\n","Epoch 21/100\n","31/33 [===========================>..] - ETA: 0s - loss: 5.0262 - mae: 5.0262\n","Epoch 21: val_loss did not improve from 4.82814\n","33/33 [==============================] - 0s 11ms/step - loss: 5.0538 - mae: 5.0538 - val_loss: 5.6226 - val_mae: 5.6226\n","Epoch 22/100\n","31/33 [===========================>..] - ETA: 0s - loss: 4.8897 - mae: 4.8897\n","Epoch 22: val_loss did not improve from 4.82814\n","33/33 [==============================] - 0s 11ms/step - loss: 4.9157 - mae: 4.9157 - val_loss: 4.9393 - val_mae: 4.9393\n","Epoch 23/100\n","31/33 [===========================>..] - ETA: 0s - loss: 4.8154 - mae: 4.8154\n","Epoch 23: val_loss improved from 4.82814 to 4.78103, saving model to best_model.h5\n","33/33 [==============================] - 0s 13ms/step - loss: 4.8233 - mae: 4.8233 - val_loss: 4.7810 - val_mae: 4.7810\n","Epoch 24/100\n","31/33 [===========================>..] - ETA: 0s - loss: 4.8657 - mae: 4.8657\n","Epoch 24: val_loss did not improve from 4.78103\n","33/33 [==============================] - 0s 11ms/step - loss: 4.8985 - mae: 4.8985 - val_loss: 4.8397 - val_mae: 4.8397\n","Epoch 25/100\n","31/33 [===========================>..] - ETA: 0s - loss: 4.7956 - mae: 4.7956\n","Epoch 25: val_loss did not improve from 4.78103\n","33/33 [==============================] - 0s 11ms/step - loss: 4.7608 - mae: 4.7608 - val_loss: 4.8510 - val_mae: 4.8510\n","Epoch 26/100\n","31/33 [===========================>..] - ETA: 0s - loss: 4.6948 - mae: 4.6948\n","Epoch 26: val_loss did not improve from 4.78103\n","33/33 [==============================] - 0s 11ms/step - loss: 4.6636 - mae: 4.6636 - val_loss: 5.0057 - val_mae: 5.0057\n","Epoch 27/100\n","31/33 [===========================>..] - ETA: 0s - loss: 4.6888 - mae: 4.6888\n","Epoch 27: val_loss did not improve from 4.78103\n","33/33 [==============================] - 0s 11ms/step - loss: 4.7117 - mae: 4.7117 - val_loss: 4.8007 - val_mae: 4.8007\n","Epoch 28/100\n","31/33 [===========================>..] - ETA: 0s - loss: 4.8520 - mae: 4.8520\n","Epoch 28: val_loss did not improve from 4.78103\n","33/33 [==============================] - 0s 11ms/step - loss: 4.8898 - mae: 4.8898 - val_loss: 4.8123 - val_mae: 4.8123\n","Epoch 29/100\n","31/33 [===========================>..] - ETA: 0s - loss: 4.7323 - mae: 4.7323\n","Epoch 29: val_loss improved from 4.78103 to 4.74428, saving model to best_model.h5\n","33/33 [==============================] - 0s 13ms/step - loss: 4.7591 - mae: 4.7591 - val_loss: 4.7443 - val_mae: 4.7443\n","Epoch 30/100\n","31/33 [===========================>..] - ETA: 0s - loss: 4.7388 - mae: 4.7388\n","Epoch 30: val_loss did not improve from 4.74428\n","33/33 [==============================] - 0s 11ms/step - loss: 4.7397 - mae: 4.7397 - val_loss: 5.3014 - val_mae: 5.3014\n","Epoch 31/100\n","31/33 [===========================>..] - ETA: 0s - loss: 4.6133 - mae: 4.6133\n","Epoch 31: val_loss did not improve from 4.74428\n","33/33 [==============================] - 0s 12ms/step - loss: 4.6371 - mae: 4.6371 - val_loss: 5.2368 - val_mae: 5.2368\n","Epoch 32/100\n","31/33 [===========================>..] - ETA: 0s - loss: 5.0128 - mae: 5.0128\n","Epoch 32: val_loss did not improve from 4.74428\n","33/33 [==============================] - 0s 11ms/step - loss: 5.0163 - mae: 5.0163 - val_loss: 4.7610 - val_mae: 4.7610\n","Epoch 33/100\n","31/33 [===========================>..] - ETA: 0s - loss: 4.6956 - mae: 4.6956\n","Epoch 33: val_loss did not improve from 4.74428\n","33/33 [==============================] - 0s 11ms/step - loss: 4.7062 - mae: 4.7062 - val_loss: 4.8117 - val_mae: 4.8117\n","Epoch 34/100\n","31/33 [===========================>..] - ETA: 0s - loss: 4.6498 - mae: 4.6498\n","Epoch 34: val_loss did not improve from 4.74428\n","33/33 [==============================] - 0s 11ms/step - loss: 4.6807 - mae: 4.6807 - val_loss: 4.9519 - val_mae: 4.9519\n","Epoch 35/100\n","31/33 [===========================>..] - ETA: 0s - loss: 4.9919 - mae: 4.9919\n","Epoch 35: val_loss did not improve from 4.74428\n","33/33 [==============================] - 0s 11ms/step - loss: 4.9856 - mae: 4.9856 - val_loss: 4.8120 - val_mae: 4.8120\n","Epoch 36/100\n","31/33 [===========================>..] - ETA: 0s - loss: 4.7155 - mae: 4.7155\n","Epoch 36: val_loss did not improve from 4.74428\n","33/33 [==============================] - 0s 11ms/step - loss: 4.7318 - mae: 4.7318 - val_loss: 4.7810 - val_mae: 4.7810\n","Epoch 37/100\n","31/33 [===========================>..] - ETA: 0s - loss: 4.7814 - mae: 4.7814\n","Epoch 37: val_loss did not improve from 4.74428\n","33/33 [==============================] - 0s 11ms/step - loss: 4.8068 - mae: 4.8068 - val_loss: 4.8288 - val_mae: 4.8288\n","Epoch 38/100\n","31/33 [===========================>..] - ETA: 0s - loss: 4.8001 - mae: 4.8001\n","Epoch 38: val_loss did not improve from 4.74428\n","33/33 [==============================] - 0s 11ms/step - loss: 4.8429 - mae: 4.8429 - val_loss: 4.8071 - val_mae: 4.8071\n","Epoch 39/100\n","31/33 [===========================>..] - ETA: 0s - loss: 4.7589 - mae: 4.7589Restoring model weights from the end of the best epoch: 29.\n","\n","Epoch 39: val_loss did not improve from 4.74428\n","33/33 [==============================] - 0s 11ms/step - loss: 4.7611 - mae: 4.7611 - val_loss: 4.7689 - val_mae: 4.7689\n","Epoch 39: early stopping\n","17/17 [==============================] - 0s 3ms/step\n","Mean Absolute Error for CNN 4.744276311965216\n"]}],"source":["# Compile the model\n","model_cnn = CNNModel.build(width=img_dims[0], height=img_dims[1], depth=img_dims[2])\n","optimizer = Adam(lr=0.001)\n","model_cnn.compile(loss='mean_absolute_error',\n","              optimizer=optimizer,\n","              metrics=['mae'])\n","\n","callbacks = [\n","    EarlyStopping(monitor='val_loss', patience=10, verbose=1, restore_best_weights=True),\n","    ModelCheckpoint(filepath='best_model.h5', monitor='val_loss', save_best_only=True, verbose=1)\n","]\n","\n","# Train the model with learning rate scheduler callback\n","# Train the model with callbacks\n","model_cnn.fit(trainX, trainY,\n","                    batch_size=64,\n","                    epochs=100,\n","                    validation_data=(testX, testY),\n","                    callbacks=callbacks)\n","\n","pred = model_cnn.predict(np.array(testX))\n","mae = mean_absolute_error(testY, pred)\n","\n","print(\"Mean Absolute Error for CNN\", mae)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"YJW6scwQoi9v"},"outputs":[],"source":["XXXXXX.save(\"MODELNAME_CLASS.keras\")"]},{"cell_type":"code","source":["def image_preprocessing(img_path):\n","\n"," #Read the image\n"," img=cv2.imread(img_path)\n","\n"," #Resize the image\n"," resized_img=cv2.resize(img,(96,96))\n","\n"," #Normalize the image\n"," normalized_img=resized_img/255\n"," #normalized_img_batch = np.expand_dims(normalized_img, axis=0)\n","\n"," return normalized_img"],"metadata":{"id":"PHxOK_a8iOf2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def label_extraction(img_name):\n"," #Extract age\n","  age=int(img_name.split(\"/\")[-1].split(\"_\")[0])\n","  if 0<age<18 :\n","    class_index=0\n","  elif 17<age<26:\n","    class_index=1\n","  elif 25<age<51:\n","    class_index=2\n","  elif 50<age<71:\n","    class_index=3\n","  else:\n","    class_index=4\n","  return class_index"],"metadata":{"id":"LFKKGrUhiVMg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["image_files = [f for f in glob.glob(utkface_path + \"/*.jpg\", recursive=True)]"],"metadata":{"id":"13HAxfvEi1zG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["features=[]\n","labels=[]\n","\n","for img_name in image_files:\n","  class_index=label_extraction(img_name)\n","  labels.append(class_index)\n","\n","  preprocessed_img=image_preprocessing(img_name)\n","  #Append data into appropriate lists\n","  features.append(preprocessed_img)\n","\n","\n","\n","#Convert lists to numpy arrays\n","features=np.asarray(features)\n","labels=np.asarray(labels)"],"metadata":{"id":"6UoXTZp8itCe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["encoded_labels=to_categorical(labels)"],"metadata":{"id":"8DLwvG90jS4Z"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["features_train, features_test, labels_train, labels_test = train_test_split(features, encoded_labels,test_size = 0.1, shuffle = True,random_state = 42)"],"metadata":{"id":"BZ4RCfnMjZE-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["vgg_classifier = VGG_Classifier.build(96,96,3,5)\n","\n","optimizer = Adam(lr=0.001)\n","vgg_classifier.compile(loss = 'categorical_crossentropy', optimizer = \"adam\", metrics = [\"accuracy\"])\n","\n","callbacks = [\n","    EarlyStopping(monitor='val_loss', patience=10, verbose=1, restore_best_weights=True),\n","    ModelCheckpoint(filepath='best_model.h5', monitor='val_loss', save_best_only=True, verbose=1)\n","]\n","\n","# Train the model with learning rate scheduler callback\n","history = vgg_classifier.fit(x = features_train, y = labels_train, epochs = 50, shuffle = True, validation_split = 0.1, callbacks = callbacks )\n","\n","\n","model_evaluation_history = vgg_classifier.evaluate(features_test, labels_test)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5tK77cSGjbrU","executionInfo":{"status":"ok","timestamp":1710266289275,"user_tz":-60,"elapsed":139091,"user":{"displayName":"Vincent Corbaux","userId":"05632967668149730282"}},"outputId":"64b2041b-0894-47a8-ee88-c9dd3d5b8641"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/50\n","343/343 [==============================] - ETA: 0s - loss: 1.7723 - accuracy: 0.5609\n","Epoch 1: val_loss improved from inf to 1.31240, saving model to best_model.h5\n","343/343 [==============================] - 12s 18ms/step - loss: 1.7723 - accuracy: 0.5609 - val_loss: 1.3124 - val_accuracy: 0.5865\n","Epoch 2/50\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["341/343 [============================>.] - ETA: 0s - loss: 1.2353 - accuracy: 0.6163\n","Epoch 2: val_loss improved from 1.31240 to 1.05338, saving model to best_model.h5\n","343/343 [==============================] - 5s 13ms/step - loss: 1.2353 - accuracy: 0.6165 - val_loss: 1.0534 - val_accuracy: 0.6505\n","Epoch 3/50\n","341/343 [============================>.] - ETA: 0s - loss: 1.1173 - accuracy: 0.6304\n","Epoch 3: val_loss improved from 1.05338 to 0.99088, saving model to best_model.h5\n","343/343 [==============================] - 5s 13ms/step - loss: 1.1177 - accuracy: 0.6300 - val_loss: 0.9909 - val_accuracy: 0.6710\n","Epoch 4/50\n","341/343 [============================>.] - ETA: 0s - loss: 1.0702 - accuracy: 0.6298\n","Epoch 4: val_loss improved from 0.99088 to 0.96874, saving model to best_model.h5\n","343/343 [==============================] - 5s 13ms/step - loss: 1.0706 - accuracy: 0.6296 - val_loss: 0.9687 - val_accuracy: 0.6620\n","Epoch 5/50\n","341/343 [============================>.] - ETA: 0s - loss: 1.0323 - accuracy: 0.6402\n","Epoch 5: val_loss improved from 0.96874 to 0.94334, saving model to best_model.h5\n","343/343 [==============================] - 5s 13ms/step - loss: 1.0324 - accuracy: 0.6406 - val_loss: 0.9433 - val_accuracy: 0.6678\n","Epoch 6/50\n","341/343 [============================>.] - ETA: 0s - loss: 1.0134 - accuracy: 0.6414\n","Epoch 6: val_loss improved from 0.94334 to 0.94186, saving model to best_model.h5\n","343/343 [==============================] - 5s 13ms/step - loss: 1.0135 - accuracy: 0.6411 - val_loss: 0.9419 - val_accuracy: 0.6727\n","Epoch 7/50\n","341/343 [============================>.] - ETA: 0s - loss: 1.0051 - accuracy: 0.6397\n","Epoch 7: val_loss improved from 0.94186 to 0.90426, saving model to best_model.h5\n","343/343 [==============================] - 5s 13ms/step - loss: 1.0048 - accuracy: 0.6395 - val_loss: 0.9043 - val_accuracy: 0.6727\n","Epoch 8/50\n","341/343 [============================>.] - ETA: 0s - loss: 0.9988 - accuracy: 0.6400\n","Epoch 8: val_loss did not improve from 0.90426\n","343/343 [==============================] - 4s 12ms/step - loss: 0.9983 - accuracy: 0.6403 - val_loss: 0.9164 - val_accuracy: 0.6645\n","Epoch 9/50\n","341/343 [============================>.] - ETA: 0s - loss: 0.9760 - accuracy: 0.6458\n","Epoch 9: val_loss did not improve from 0.90426\n","343/343 [==============================] - 4s 12ms/step - loss: 0.9767 - accuracy: 0.6457 - val_loss: 0.9655 - val_accuracy: 0.6505\n","Epoch 10/50\n","341/343 [============================>.] - ETA: 0s - loss: 0.9739 - accuracy: 0.6465\n","Epoch 10: val_loss improved from 0.90426 to 0.90230, saving model to best_model.h5\n","343/343 [==============================] - 5s 13ms/step - loss: 0.9745 - accuracy: 0.6463 - val_loss: 0.9023 - val_accuracy: 0.6710\n","Epoch 11/50\n","341/343 [============================>.] - ETA: 0s - loss: 0.9712 - accuracy: 0.6472\n","Epoch 11: val_loss improved from 0.90230 to 0.89790, saving model to best_model.h5\n","343/343 [==============================] - 5s 13ms/step - loss: 0.9715 - accuracy: 0.6468 - val_loss: 0.8979 - val_accuracy: 0.6727\n","Epoch 12/50\n","341/343 [============================>.] - ETA: 0s - loss: 0.9619 - accuracy: 0.6453\n","Epoch 12: val_loss improved from 0.89790 to 0.89184, saving model to best_model.h5\n","343/343 [==============================] - 5s 13ms/step - loss: 0.9615 - accuracy: 0.6453 - val_loss: 0.8918 - val_accuracy: 0.6678\n","Epoch 13/50\n","341/343 [============================>.] - ETA: 0s - loss: 0.9587 - accuracy: 0.6511\n","Epoch 13: val_loss did not improve from 0.89184\n","343/343 [==============================] - 4s 12ms/step - loss: 0.9587 - accuracy: 0.6515 - val_loss: 0.9059 - val_accuracy: 0.6579\n","Epoch 14/50\n","341/343 [============================>.] - ETA: 0s - loss: 0.9525 - accuracy: 0.6568\n","Epoch 14: val_loss did not improve from 0.89184\n","343/343 [==============================] - 4s 12ms/step - loss: 0.9537 - accuracy: 0.6562 - val_loss: 0.8944 - val_accuracy: 0.6604\n","Epoch 15/50\n","341/343 [============================>.] - ETA: 0s - loss: 0.9480 - accuracy: 0.6558\n","Epoch 15: val_loss improved from 0.89184 to 0.89090, saving model to best_model.h5\n","343/343 [==============================] - 5s 13ms/step - loss: 0.9476 - accuracy: 0.6562 - val_loss: 0.8909 - val_accuracy: 0.6661\n","Epoch 16/50\n","341/343 [============================>.] - ETA: 0s - loss: 0.9575 - accuracy: 0.6560\n","Epoch 16: val_loss did not improve from 0.89090\n","343/343 [==============================] - 4s 12ms/step - loss: 0.9573 - accuracy: 0.6558 - val_loss: 0.9031 - val_accuracy: 0.6661\n","Epoch 17/50\n","341/343 [============================>.] - ETA: 0s - loss: 0.9543 - accuracy: 0.6506\n","Epoch 17: val_loss did not improve from 0.89090\n","343/343 [==============================] - 4s 12ms/step - loss: 0.9538 - accuracy: 0.6506 - val_loss: 0.8984 - val_accuracy: 0.6628\n","Epoch 18/50\n","341/343 [============================>.] - ETA: 0s - loss: 0.9396 - accuracy: 0.6595\n","Epoch 18: val_loss did not improve from 0.89090\n","343/343 [==============================] - 4s 12ms/step - loss: 0.9391 - accuracy: 0.6596 - val_loss: 0.8934 - val_accuracy: 0.6784\n","Epoch 19/50\n","341/343 [============================>.] - ETA: 0s - loss: 0.9473 - accuracy: 0.6579\n","Epoch 19: val_loss improved from 0.89090 to 0.89032, saving model to best_model.h5\n","343/343 [==============================] - 5s 13ms/step - loss: 0.9473 - accuracy: 0.6581 - val_loss: 0.8903 - val_accuracy: 0.6710\n","Epoch 20/50\n","341/343 [============================>.] - ETA: 0s - loss: 0.9397 - accuracy: 0.6645\n","Epoch 20: val_loss did not improve from 0.89032\n","343/343 [==============================] - 4s 12ms/step - loss: 0.9386 - accuracy: 0.6650 - val_loss: 0.9241 - val_accuracy: 0.6612\n","Epoch 21/50\n","341/343 [============================>.] - ETA: 0s - loss: 0.9331 - accuracy: 0.6631\n","Epoch 21: val_loss did not improve from 0.89032\n","343/343 [==============================] - 4s 12ms/step - loss: 0.9343 - accuracy: 0.6625 - val_loss: 0.8948 - val_accuracy: 0.6702\n","Epoch 22/50\n","341/343 [============================>.] - ETA: 0s - loss: 0.9404 - accuracy: 0.6639\n","Epoch 22: val_loss did not improve from 0.89032\n","343/343 [==============================] - 4s 12ms/step - loss: 0.9402 - accuracy: 0.6639 - val_loss: 0.8947 - val_accuracy: 0.6710\n","Epoch 23/50\n","341/343 [============================>.] - ETA: 0s - loss: 0.9508 - accuracy: 0.6587\n","Epoch 23: val_loss did not improve from 0.89032\n","343/343 [==============================] - 4s 12ms/step - loss: 0.9503 - accuracy: 0.6589 - val_loss: 0.8905 - val_accuracy: 0.6727\n","Epoch 24/50\n","341/343 [============================>.] - ETA: 0s - loss: 0.9364 - accuracy: 0.6617\n","Epoch 24: val_loss did not improve from 0.89032\n","343/343 [==============================] - 4s 12ms/step - loss: 0.9364 - accuracy: 0.6617 - val_loss: 0.9045 - val_accuracy: 0.6653\n","Epoch 25/50\n","341/343 [============================>.] - ETA: 0s - loss: 0.9437 - accuracy: 0.6651\n","Epoch 25: val_loss did not improve from 0.89032\n","343/343 [==============================] - 4s 12ms/step - loss: 0.9434 - accuracy: 0.6655 - val_loss: 0.9100 - val_accuracy: 0.6678\n","Epoch 26/50\n","341/343 [============================>.] - ETA: 0s - loss: 0.9326 - accuracy: 0.6679\n","Epoch 26: val_loss did not improve from 0.89032\n","343/343 [==============================] - 4s 12ms/step - loss: 0.9327 - accuracy: 0.6676 - val_loss: 0.9128 - val_accuracy: 0.6669\n","Epoch 27/50\n","341/343 [============================>.] - ETA: 0s - loss: 0.9327 - accuracy: 0.6693\n","Epoch 27: val_loss did not improve from 0.89032\n","343/343 [==============================] - 4s 12ms/step - loss: 0.9326 - accuracy: 0.6693 - val_loss: 0.9000 - val_accuracy: 0.6661\n","Epoch 28/50\n","341/343 [============================>.] - ETA: 0s - loss: 0.9323 - accuracy: 0.6639\n","Epoch 28: val_loss did not improve from 0.89032\n","343/343 [==============================] - 4s 12ms/step - loss: 0.9320 - accuracy: 0.6641 - val_loss: 0.8959 - val_accuracy: 0.6678\n","Epoch 29/50\n","341/343 [============================>.] - ETA: 0s - loss: 0.9374 - accuracy: 0.6629Restoring model weights from the end of the best epoch: 19.\n","\n","Epoch 29: val_loss did not improve from 0.89032\n","343/343 [==============================] - 4s 13ms/step - loss: 0.9375 - accuracy: 0.6631 - val_loss: 0.9007 - val_accuracy: 0.6792\n","Epoch 29: early stopping\n","43/43 [==============================] - 1s 25ms/step - loss: 0.8956 - accuracy: 0.6780\n"]}]},{"cell_type":"code","source":["vgg_classifier.save(\"VGG_classifier.keras\")"],"metadata":{"id":"Wzo6kAu6kAs4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model_resnet_0 = tf.keras.models.load_model(\"/content/drive/MyDrive/Age_Detection_Project/ResNet_0_17.keras\")\n","model_resnet_1 = tf.keras.models.load_model(\"/content/drive/MyDrive/Age_Detection_Project/ResNet_26_50.keras\")\n","model_effnet = tf.keras.models.load_model(\"/content/drive/MyDrive/Age_Detection_Project/EfficientNet_18_25.keras\")\n","model_cnn = tf.keras.models.load_model(\"/content/drive/MyDrive/Age_Detection_Project/CNN_51_70.keras\")\n","model_vggnet = tf.keras.models.load_model(\"/content/drive/MyDrive/Age_Detection_Project/VGG_71_120.keras\")\n","vgg_classifier = tf.keras.models.load_model(\"/content/drive/MyDrive/Age_Detection_Project/VGG_classifier.keras\")"],"metadata":{"id":"YEkJW116u_3K","executionInfo":{"status":"ok","timestamp":1710337423768,"user_tz":-60,"elapsed":72246,"user":{"displayName":"Vincent Corbaux","userId":"05632967668149730282"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["test_images = [f for f in glob.glob(\"/content/drive/MyDrive/Age_Detection_Project/test_images\" + \"/*.jpg\", recursive=True)]"],"metadata":{"id":"eE6X6oJckVCM","executionInfo":{"status":"ok","timestamp":1710337423768,"user_tz":-60,"elapsed":13,"user":{"displayName":"Vincent Corbaux","userId":"05632967668149730282"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["preds_mae = []\n","for image in test_images:\n","  img = cv2.imread(image)\n","  age=int(image.split(\"/\")[-1].split(\"_\")[2])\n","  # Redimensionner l'image\n","  resized_img = cv2.resize(img, (96, 96))\n","  # Normaliser l'image\n","  normalized_img = resized_img / 255.0\n","\n","  # Ajouter une dimension de lot supplémentaire\n","  normalized_img_batch = np.expand_dims(normalized_img, axis=0)\n","\n","  predictions = np.array(vgg_classifier.predict(normalized_img_batch))\n","  max_index = np.argmax(predictions)\n","\n","  if max_index == 0:\n","    pred = model_resnet_0.predict(normalized_img_batch)\n","    preds_mae.append(np.abs(age - pred))\n","  elif max_index == 1:\n","    pred = model_effnet.predict(normalized_img_batch)\n","    preds_mae.append(np.abs(age - pred))\n","  elif max_index == 2:\n","    pred = model_resnet_1.predict(normalized_img_batch)\n","    preds_mae.append(np.abs(age - pred))\n","  elif max_index == 3:\n","    pred = model_cnn.predict(normalized_img_batch)\n","    preds_mae.append(np.abs(age - pred))\n","  elif max_index == 4:\n","    pred = model_vggnet.predict(normalized_img_batch)\n","    preds_mae.append(np.abs(age - pred))\n","\n","mae_cascade = np.mean(preds_mae)\n","\n","print(\"MAE for cascade architecture: \", mae_cascade)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3A_5ofv-m_P3","executionInfo":{"status":"ok","timestamp":1710337738460,"user_tz":-60,"elapsed":289852,"user":{"displayName":"Vincent Corbaux","userId":"05632967668149730282"}},"outputId":"d19bafb3-800c-4cca-f0ec-415949c587ca"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 3s 3s/step\n","1/1 [==============================] - 0s 182ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 2s 2s/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 243ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 17ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 17ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 17ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 17ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 24ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 17ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 17ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 17ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 17ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 17ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 24ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 26ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 1s 914ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 17ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 17ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 16ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 25ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 25ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 24ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 24ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 24ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 24ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 17ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 17ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 17ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 17ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 17ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 24ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 24ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 25ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 25ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 25ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 3s 3s/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 17ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 25ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 25ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 17ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 26ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 29ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 25ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 24ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 16ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 24ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 17ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 17ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 24ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 17ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 25ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 24ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 24ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 24ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 17ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 17ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 25ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 17ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 24ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 25ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 24ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 17ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 17ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 26ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 17ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 17ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 24ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 24ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 24ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 24ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 17ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 17ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 17ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 26ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 17ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 17ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 24ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 17ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 24ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 22ms/step\n","MAE for cascade architecture:  14.332493\n"]}]}],"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"V100","authorship_tag":"ABX9TyMfDsjBaPfAH7PUF1ro5nBj"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}